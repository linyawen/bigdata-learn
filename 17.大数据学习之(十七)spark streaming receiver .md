

# spark streaming receiver 模式

1. spark Streaming：
   https://spark.apache.org/docs/2.3.4/streaming-programming-guide.html

   缺点：

   1. 使用微批处理数据、很难支持毫秒级延迟，只能到100ms左右。
   2. 不支持使用SQL方式处理数据。
   3. dstream算子的 api，底层是rdd，编程模型比较复杂。
   4. 只支持 processing time（spark接收时间） 不支持event time（事件产生时间）
   5. 

2. (todo)基于以上缺点，大多数场景使用  structured streaming 更好
   
   https://spark.apache.org/docs/2.3.4/structured-streaming-programming-guide.html

环境：本地idea运行

## 引入依赖

```xml
<dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.11</artifactId>
            <version>2.3.4</version>
</dependency>
```

## 启动nc

模拟数据的生产者 

```shell
#node1
nc -l 8889
```

## 执行demo

连上node1的nc端口后，从node1 每次输入一行数据，这个demo 每5s计算一批次数据的worldCount

```scala
val conf: SparkConf = new SparkConf().setAppName("sdfdsf").setMaster("local[9]")
    //当本地运行时
    //local[n]  2个就够了，不能只写local，local代表单线程，
    // 接收数据和计算必须运行在不同线程，不然会被阻塞
    //从 spark webUI 能看到 启动了2个job，一个计算一个receiver
    // 1个给receiverjob的task，
    // 另一个给beatch计算的job（只不过如 果batch比较大，你期望n>2,因为多出来的线程可以跑并行的batch@job@task）
    
    //微批的流式计算，时间去定义批次 （while->时间间隔触发job）
    val ssc = new StreamingContext(conf,Seconds(5))
    ssc.sparkContext.setLogLevel("ERROR")
	//连上node1的nc
    val dataDStream: ReceiverInputDStream[String] = ssc.socketTextStream("node1",8889)
    //hello world
    val flatDStream: DStream[String] = dataDStream.flatMap(_.split(" "))
    val resDStream: DStream[(String, Int)] = flatDStream.map((_,1)).reduceByKey(_+_)
    resDStream.print()  //输出算子

//    val res: DStream[(String, String)] = dataDStream.map(_.split(" ")).map(vars=>{
//      Thread.sleep(20000)
//      (vars(0),vars(1))
//    })
//
//    res.print()

    //触发异步job，while 时间间隔执行 上面的计算任务，并且输出结果
    ssc.start()
    ssc.awaitTermination()
```

## 结果分析

每5s执行一次计算，每次计算只包含这5s输入的批次数据。

> 缺点：
>
> 1.每个批次单独计算，如果不知道这个批次具体由哪几条数据计算得到，当批次结果入库错误时，从而无法重复计算。
>
> 2.每个批次的job线性阻塞，一个批次耗时会导致下一次批次计算延迟。（线程的多少只影响一次批次计算内的task数）

![](D:\学习资料\大数据学习笔记\static\sparkStreaming_1.png)

## 优化

​		调整批次大小 以及计算代码逻辑提高速度，尽量减少积压

尽量数据来了就计算，计算了就出结果。

##  sparkWebUI 的storage /streaming/模块

如下显示如何插件批次的job延迟

![image-20230227203810070](D:\学习资料\大数据学习笔记\static\sparkStreaming_2.png)

![image-20230227203810070](D:\学习资料\大数据学习笔记\static\sparkStreaming_3.png)